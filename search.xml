<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Front-end Handbook HTML]]></title>
    <url>%2F2018%2F03%2F02%2FFront-end-Handbook-HTML%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[TypeScript Introduction]]></title>
    <url>%2F2018%2F03%2F01%2FTypeScript-Introduction%2F</url>
    <content type="text"><![CDATA[What is TypeScriptBy definition, “TypeScript is JavaScript for application-scale development.” TypeScript is a strongly typed, object oriented, compiled language. It was designed by Anders Hejlsberg (designer of C#) at Microsoft. TypeScript is both a language and a set of tools. TypeScript is a typed superset of JavaScript compiled to JavaScript. In other words, TypeScript is JavaScript plus some additional features. PrerequisitesTo use TypeScript, you should have a good understanding of OOP concepts and basic JavaScript, to make the most of this tutorial. Relation to JavaScriptJavaScript is standardized through the ECMAScript standards. Not all browsers in use support all features of newer ECMAScript standards (see this table). TypeScript supports new ECMAScript standards and compiles them to (older) ECMAScript targets of your choosing (current targets are 3, 5 and 6 [a.k.a. 2015]). This means that you can use features of ES2015 and beyond, like modules, lambda functions, classes, the spread operator, destructuring, today. It also adds type support of course, which is not part of any ECMAScript standard and may likely never be due to the interpreted nature instead of compiled nature of JavaScript. The type system of TypeScript is relatively rich and includes: interfaces, enums, hybrid types, generics, union and intersection types, access modifiers and much more. The official website of TypeScript gives an overview of these features. Are there other technologies like it?There’s CoffeeScript, but that really serves a different purpose. IMHO, CoffeeScript provides readability for humans, but TypeScript also provides deep readability for tools through its optional static typing. There’s also Dart but that’s a full on replacement for JavaScript (though it can produce JavaScript code). FeaturesOptionally static typing and type inferenceJavaScript is dynamically typed. This means JavaScript does not know what type a variable is until it is actually instantiated at run-time. This also means that it may be too late. TypeScript adds type support to JavaScript. Bugs that are caused by false assumptions of some variable being of a certain type can be completely eradicated if you play your cards right; how strict you type your code or if you type your code at all is up to you. TypeScript makes typing a bit easier and a lot less explicit by the usage of type inference. For example: var x = “hello” in TypeScript is the same as var x : string = “hello”. The type is simply inferred from its use. Even it you don’t explicitly type the types, they are still there to save you from doing something which otherwise would result in a run-time error. TypeScript is optionally typed by default. For example function divideByTwo(x) { return x / 2 } is a valid function in TypeScript which can be called with any kind of parameter, even though calling it with a string will obviously result in a runtime error. Just like you are used to in JavaScript. This works, because when no type was explicitly assigned and the type could not be inferred, like in the divideByTwo example, TypeScript will implicitly assign the type any. This means the divideByTwo function’s type signature automatically becomes function divideByTwo(x : any) : any There is a compiler flag to disallow this behavior: --noImplicitAny. Enabling this flag gives you a greater degree of safety, but also means you will have to do more typing. InterfacesThe interface keyword is used to declare an interface. Here is the syntax to declare an interface Declaring InterfacesSyntax12interface interface_name &#123;&#125; Example: Interface and Objects12345678910111213141516171819202122232425interface IPerson &#123;firstName:string,lastName:string,sayHi: ()=&gt;string&#125;var customer:IPerson = &#123;firstName:&quot;Tom&quot;,lastName:&quot;Hanks&quot;,sayHi: ():string =&gt;&#123;return &quot;Hi there&quot;&#125;&#125;console.log(&quot;Customer Object &quot;)console.log(customer.firstName)console.log(customer.lastName)console.log(customer.sayHi())var employee:IPerson = &#123;firstName:&quot;Jim&quot;,lastName:&quot;Blakes&quot;,sayHi: ():string =&gt;&#123;return &quot;Hello!!!&quot;&#125;&#125;console.log(&quot;Employee Object &quot;)console.log(employee.firstName) console.log(employee.lastName) Interfaces and InheritanceSyntax: Single Interface Inheritance 1Child_interface_name extends super_interface_name Syntax: Multiple Interface Inheritance12Child_interface_name extends super_interface1_name,super_interface2_name,…,super_interfaceN_name Example: Simple Interface Inheritance 123456789101112interface Person &#123;age:number&#125;interface Musician extends Person &#123;instrument:string&#125;var drummer = &lt;Musician&gt;&#123;&#125;;drummer.age = 27drummer.instrument = "Drums"console.log("Age: "+drummer.age) console.log("Instrument: "+drummer.instrument) On compiling, it will generate following JavaScript code. 123456//Generated by typescript 1.8.10var drummer = &#123;&#125;;drummer.age = 27;drummer.instrument = "Drums";console.log("Age: " + drummer.age);console.log("Instrument: " + drummer.instrument); ClassesTypescript gives built in support for this concept called class. JavaScript ES5 or earlier didn’t support classes. Typescript gets this feature from ES6. Creating classesSyntax123class class_name &#123;//class scope&#125; A class definition can include the following Fields − A field is any variable declared in a class. Fields represent data pertaining to objects Constructors − Responsible for allocating memory for the objects of the class Functions − Functions represent actions an object can take. They are also at times referred to as methods Example: Declaring a class1234567891011121314class Car &#123;//fieldengine:string;//constructorconstructor(engine:string) &#123;this.engine = engine&#125;//functiondisp():void &#123;console.log(&quot;Engine is : &quot;+this.engine)&#125;&#125; Enhanced IDE supportThe development experience with TypeScript is a great improvement over JavaScript. The IDE is informed in real-time by the TypeScript compiler on its rich type information. This gives a couple of major advantages. For example, with TypeScript you can safely do refactorings like renames across your entire codebase. Through code completion you can get inline help on whatever functions a library might offer. No more need to remember them or look them up in online references. Compilation errors are reported directly in the IDE with a red squiggly line while you are busy coding. All in all this allows for a significant gain in productivity compared to working with JavaScript. One can spend more time coding and less time debugging. There is a wide range of IDEs that have excellent support for TypeScript, like Visual Studio &amp; VS code, Atom, Sublime, and IntelliJ/WebStorm. Strict null checksRuntime errors of the form cannot read property ‘x’ of undefined or undefined is not a function are very commonly caused by bugs in JavaScript code. Out of the box TypeScript already reduces the probability of these kinds of errors occurring, since one cannot use a variable that is not known to the TypeScript compiler (with the exception of properties of any typed variables). It is still possible though to mistakenly utilize a variable that is set to undefined. However, with the 2.0 version of TypeScript you can eliminate these kinds of errors all together through the usage of non-nullable types. This works as follows: With strict null checks enabled (--strictNullChecks compiler flag) the TypeScript compiler will not allow undefined to be assigned to a variable unless you explicitly declare it to be of nullable type. For example, let x : number = undefined will result in a compile error. This fits perfectly with type theory, since undefined is not a number. One can define x to be a sum type of number and undefined to correct this: let x : number | undefined = undefined. CompilationTo use TypeScript you need a build process to compile to JavaScript code. The build process generally takes only a couple of seconds depending of course on the size of your project. The TypeScript compiler supports incremental compilation (--watch compiler flag), so that all subsequent changes can be compiled at greater speed. The TypeScript compiler can inline source map information in the generated .js files or create separate .map files. Source map information can be used by debugging utilities like the Chrome DevTools and other IDE’s to relate the lines in the JavaScript to the ones that generated them in the TypeScript. This makes it possible for you to set breakpoints and inspect variables during runtime directly on your TypeScript code. Source map information works pretty good, it was around long before TypeScript, but debugging TypeScript is generally not as great as when using JavaScript directly. Converting from JavaScript to TypeScriptAny .js file can be renamed to a .ts and ran through the TypeScript compiler to get syntactically the same JavaScript code as an output (if it was syntactically correct in the first place). Even when the TypeScript compiler gets compilation errors it will still produce a .js file. It can even accept .js files as input with the --allowJs flag. This allows you to start with TypeScript right away. Unfortunately compilation errors are likely to occur in the beginning. One does need to remember that these are not show-stopping errors like you may be used to with other compilers. Installing TypeScriptThere are two main ways to get the TypeScript tools: Via npm (the Node.js package manager) By installing TypeScript’s Visual Studio plugins For NPM users: npm install -g typescript Building your first TypeScript fileIn your editor, type the following JavaScript code in greeter.ts: 1234567function greeter(person) &#123;return "Hello, " + person;&#125;let user = "Jane User";document.body.innerHTML = greeter(user); Compiling your codeWe used a .ts extension, but this code is just JavaScript. You could have copy/pasted this straight out of an existing JavaScript app. At the command line, run the TypeScript compiler: tsc greeter.ts The result will be a file greeter.js which contains the same JavaScript that you fed in. We’re up and running using TypeScript in our JavaScript app! ResourcesTypeScript Playground ReferencesTypeScript TutorialTypeScript Handbook]]></content>
      <categories>
        <category>Technology</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
        <tag>TypeScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Front-end Handbook JavaScript]]></title>
    <url>%2F2018%2F03%2F01%2FFront-end-Handbook-JavaScript%2F</url>
    <content type="text"><![CDATA[Explain how ‘this’ works in JavaScriptThere’s no simple explanation for this; it is one of the most confusing concepts in JavaScript. A hand-wavey explanation is that the value of this depends on how the function is called. I have read many explanations on this online, and I found Arnav Aggrawal’s explanation to be the clearest. The following rules are applied: If the new keyword is used when calling the function, this inside the function is a brand new object. If apply, call, or bind are used to call/create a function, this inside the function is the object that is passed in as the argument. If a function is called as a method, such as obj.method() — this is the object that the function is a property of. If a function is invoked as a free function invocation, meaning it was invoked without any of the conditions present above, this is the global object. In a browser, it is the window object. If in strict mode (‘use strict’), this will be undefined instead of the global object. If multiple of the above rules apply, the rule that is higher wins and will set the this value. If the function is an ES2015 arrow function, it ignores all the rules above and receives the this value of its surrounding scope at the time it is created. Referenceshttps://codeburst.io/the-simple-rules-to-this-in-javascript-35d97f31bde3https://stackoverflow.com/a/3127440/1751946 What’s the difference between an “attribute” and a “property”?Attributes are defined on the HTML markup but properties are defined on the DOM. To illustrate the difference, imagine we have this text field in our HTML: &lt; input type=”text” value=”Hello”&gt;.123const input = document.querySelector('input');console.log(input.getAttribute('value')); // Helloconsole.log(input.value); // Hello But after you change the value of the text field by adding “World!” to it, this becomes:12console.log(input.getAttribute('value')); // Helloconsole.log(input.value); // Hello World! Referenceshttps://stackoverflow.com/questions/6003819/properties-and-attributes-in-html What is the difference between == and ===?== is the abstract equality operator while === is the strict equality operator. The == operator will compare for equality after doing any necessary type conversions. The === operator will not do type conversion, so if two values are not the same type === will simply return false. When using ==, funky things can happen, such as: 1234561 == '1'; // true1 == [1]; // true1 == true; // true0 == ''; // true0 == '0'; // true0 == false; // true My advice is never to use the == operator, except for convenience when comparing against null or undefined, where a == null will return true if a is null or undefined. 123var a = null;console.log(a == null); // trueconsole.log(a == undefined); // true Referenceshttps://stackoverflow.com/questions/359494/which-equals-operator-vs-should-be-used-in-javascript-comparisons What is “use strict”;? What are the advantages and disadvantages to using it?‘use strict’ is a statement used to enable strict mode to entire scripts or individual functions. Strict mode is a way to opt in to a restricted variant of JavaScript. Advantages: Makes it impossible to accidentally create global variables.Makes assignments which would otherwise silently fail to throw an exception.Makes attempts to delete undeletable properties throw (where before the attempt would simply have no effect).Requires that function parameter names be unique.this is undefined in the global context.It catches some common coding bloopers, throwing exceptions.It disables features that are confusing or poorly thought out. Disadvantages: Many missing features that some developers might be used to.No more access to function.caller and function.arguments.Concatenation of scripts written in different strict modes might cause issues.Overall, I think the benefits outweigh the disadvantages, and I never had to rely on the features that strict mode blocks. I would recommend using strict mode. Referenceshttp://2ality.com/2011/10/strict-mode-hatred.htmlhttp://lucybain.com/blog/2014/js-use-strict/ Explain what a single page app is and how to make one SEO-friendly.Web developers these days refer to the products they build as web apps, rather than websites. While there is no strict difference between the two terms, web apps tend to be highly interactive and dynamic, allowing the user to perform actions and receive a response for their action. Traditionally, the browser receives HTML from the server and renders it. When the user navigates to another URL, a full-page refresh is required and the server sends fresh new HTML for the new page. This is called server-side rendering. However in modern SPAs, client-side rendering is used instead. The browser loads the initial page from the server, along with the scripts (frameworks, libraries, app code) and stylesheets required for the whole app. When the user navigates to other pages, a page refresh is not triggered. The URL of the page is updated via the HTML5 History API. New data required for the new page, usually in JSON format, is retrieved by the browser via AJAX requests to the server. The SPA then dynamically updates the page with the data via JavaScript, which it has already downloaded in the initial page load. This model is similar to how native mobile apps work. The benefits: The app feels more responsive and users do not see the flash between page navigations due to full-page refreshes.Fewer HTTP requests are made to the server, as the same assets do not have to be downloaded again for each page load.Clear separation of the concerns between the client and the server; you can easily build new clients for different platforms (e.g. mobile, chatbots, smart watches) without having to modify the server code. You can also modify the technology stack on the client and server independently, as long as the API contract is not broken. The downsides: Heavier initial page load due to loading of framework, app code, and assets required for multiple pages.There’s an additional step to be done on your server which is to configure it to route all requests to a single entry point and allow client-side routing to take over from there.SPAs are reliant on JavaScript to render content, but not all search engines execute JavaScript during crawling, and they may see empty content on your page. This inadvertently hurts the Search Engine Optimization (SEO) of your app. However, most of the time, when you are building apps, SEO is not the most important factor, as not all the content needs to be indexable by search engines. To overcome this, you can either server-side render your app or use services such as Prerender to “render your javascript in a browser, save the static HTML, and return that to the crawlers”. Referenceshttps://github.com/grab/front-end-guide#single-page-apps-spashttp://stackoverflow.com/questions/21862054/single-page-app-advantages-and-disadvantageshttp://blog.isquaredsoftware.com/presentations/2016-10-revolution-of-web-dev/https://medium.freecodecamp.com/heres-why-client-side-rendering-won-46a349fadb52 What are the pros and cons of using Promises instead of callbacks?Pros Avoid callback hell which can be unreadable.Makes it easy to write sequential asynchronous code that is readable with .then().Makes it easy to write parallel asynchronous code with Promise.all(). Cons Slightly more complex code (debatable).In older browsers where ES2015 is not supported, you need to load a polyfill in order to use it. Explain the difference between synchronous and asynchronous functions.Synchronous functions are blocking while asynchronous functions are not. In synchronous functions, statements complete before the next statement is run. In this case the program is evaluated exactly in order of the statements and execution of the program is paused if one of the statements take a very long time. Asynchronous functions usually accept a callback as a parameter and execution continues on the next line immediately after the asynchronous function is invoked. The callback is only invoked when the asynchronous operation is complete and the call stack is empty. Heavy duty operations such as loading data from a web server or querying a database should be done asynchronously so that the main thread can continue executing other operations instead of blocking until that long operation to complete (in the case of browsers, the UI will freeze). Explain the differences on the usage of foo between function foo() {} and var foo = function() {}The former is a function declaration while the latter is a function expression. The key difference is that function declarations have its body hoisted but the bodies of function expressions are not (they have the same hoisting behaviour as variables). For more explanation on hoisting, refer to the question above on hoisting. If you try to invoke a function expression before it is defined, you will get an Uncaught TypeError: XXX is not a function error. Function Declaration1234foo(); // 'FOOOOO'function foo() &#123;console.log('FOOOOO');&#125; Function Expression1234foo(); // Uncaught TypeError: foo is not a functionvar foo = function() &#123;console.log(&apos;FOOOOO&apos;);&#125;; Referenceshttps://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/function What are the differences between null and undefined?undefined undefined means, value of the variable is not defined. JavaScript has a global variable undefined whose value is “undefined” and typeof undefined is also “undefined”. Remember, undefined is not a constant or a keyword. undefined is a type with exactly one value: undefined. Assigning a new value to it does not change the value of the type undefined. 8 Ways to get Undefined: A declared variable without assigning any value to it. Implicit returns of functions due to missing return statements. return statements that do not explicitly return anything. Lookups of non-existent properties in an object. Function parameters that have not passed. Anything that has been set to the value of undefined. Any expression in the form of void(expression) The value of the global variable undefined null null means empty or non-existent value which is used by programmers to indicate “no value”. null is a primitive value and you can assign null to any variable. null is not an object, it is a primitive value. For example, you cannot add properties to it. Sometimes people wrongly assume that it is an object, because typeof null returns “object”. Btw, null == undefined. Does JavaScript pass parameter by value or by reference?Primitive type (string, number, etc.) are passed by value and objects are passed by reference. If you change a property of the passed object, the change will be affected. However, you assign a new object to the passed object, the changes will not be reflected. 123456789101112131415161718192021222324var num = 10,name = "Addy Osmani",obj1 = &#123;value: "first value"&#125;,obj2 = &#123;value: "second value"&#125;,obj3 = obj2;function change(num, name, obj1, obj2) &#123;num = num * 10;name = "Paul Irish";obj1 = obj2;obj2.value = "new value";&#125;change(num, name, obj1, obj2);console.log(num); // 10console.log(name);// "Addy Osmani"console.log(obj1.value);//"first value"console.log(obj2.valuee);//"new value"console.log(obj3.valuee);//"new value"]]></content>
      <categories>
        <category>Technology</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Tutorial(2) -- Define a container with Dockerfile]]></title>
    <url>%2F2018%2F02%2F16%2FDocker-Tutorial-Define-a-container-with-Dockerfile%2F</url>
    <content type="text"><![CDATA[Define a container with DockerfileCreate an empty directory. Change directories (cd) into the new directory, create a file called Dockerfile, copy-and-paste the following content into that file, and save it. Take note of the comments that explain each statement in your new Dockerfile. 1234567891011121314151617181920# Use an official Python runtime as a parent imageFROM python:2.7-slim# Set the working directory to /appWORKDIR /app# Copy the current directory contents into the container at /appADD . /app# Install any needed packages specified in requirements.txtRUN pip install --trusted-host pypi.python.org -r requirements.txt# Make port 80 available to the world outside this containerEXPOSE 80# Define environment variableENV NAME World# Run app.py when the container launchesCMD [&quot;python&quot;, &quot;app.py&quot;] This Dockerfile refers to a couple of files we haven’t created yet, namely app.py and requirements.txt. Let’s create those next. The app itselfCreate two more files, requirements.txt and app.py, and put them in the same folder with the Dockerfile. This completes our app, which as you can see is quite simple. When the above Dockerfile is built into an image, app.py and requirements.txt is present because of that Dockerfile’s ADD command, and the output from app.py is accessible over HTTP thanks to the EXPOSE command. requirements.txt FlaskRedis app.py123456789101112131415161718192021222324from flask import Flaskfrom redis import Redis, RedisErrorimport osimport socket# Connect to Redisredis = Redis(host=&quot;redis&quot;, db=0, socket_connect_timeout=2, socket_timeout=2)app = Flask(__name__)@app.route(&quot;/&quot;)def hello():try:visits = redis.incr(&quot;counter&quot;)except RedisError:visits = &quot;&lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt;&quot;html = &quot;&lt;h3&gt;Hello &#123;name&#125;!&lt;/h3&gt;&quot; \&quot;&lt;b&gt;Hostname:&lt;/b&gt; &#123;hostname&#125;&lt;br/&gt;&quot; \&quot;&lt;b&gt;Visits:&lt;/b&gt; &#123;visits&#125;&quot;return html.format(name=os.getenv(&quot;NAME&quot;, &quot;world&quot;), hostname=socket.gethostname(), visits=visits)if __name__ == &quot;__main__&quot;:app.run(host=&apos;0.0.0.0&apos;, port=80) Now we see that pip install -r requirements.txt installs the Flask and Redis libraries for Python, and the app prints the environment variable NAME, as well as the output of a call to socket.gethostname(). Finally, because Redis isn’t running (as we’ve only installed the Python library, and not Redis itself), we should expect that the attempt to use it here fails and produces the error message. That’s it! You don’t need Python or anything in requirements.txt on your system, nor does building or running this image install them on your system. It doesn’t seem like you’ve really set up an environment with Python and Flask, but you have. Build the appWe are ready to build the app. Make sure you are still at the top level of your new directory. Here’s what ls should show: $ lsDockerfile app.py requirements.txt Now run the build command. This creates a Docker image, which we’re going to tag using -t so it has a friendly name. docker build -t friendlyhello . Where is your built image? It’s in your machine’s local Docker image registry: $ docker image ls REPOSITORY TAG IMAGE IDfriendlyhello latest 326387cea398 Run the appRun the app, mapping your machine’s port 4000 to the container’s published port 80 using -p: docker run -p 4000:80 friendlyhello You should see a message that Python is serving your app at http://0.0.0.0:80. But that message is coming from inside the container, which doesn’t know you mapped port 80 of that container to 4000, making the correct URL http://localhost:4000. Go to that URL in a web browser to see the display content served up on a web page. Note: If you are using Docker Toolbox on Windows 7, use the Docker Machine IP instead of localhost. For example, http://192.168.99.100:4000/. To find the IP address, use the command docker-machine ip. You can also use the curl command in a shell to view the same content. 123$ curl http://localhost:4000&lt;h3&gt;Hello World!&lt;/h3&gt;&lt;b&gt;Hostname:&lt;/b&gt; 8fc990912a14&lt;br/&gt;&lt;b&gt;Visits:&lt;/b&gt; &lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt; Now let’s run the app in the background, in detached mode: docker run -d -p 4000:80 friendlyhello You get the long container ID for your app and then are kicked back to your terminal. Your container is running in the background. You can also see the abbreviated container ID with docker container ls (and both work interchangeably when running commands): $ docker container ls CONTAINER ID IMAGE COMMAND CREATED 1fa4ab2cf395 friendlyhello “python app.py” 28 seconds ago Notice that CONTAINER ID matches what’s on http://localhost:4000. Now use docker container stop to end the process, using the CONTAINER ID, like so: docker container stop 1fa4ab2cf395 Share your imageA registry is a collection of repositories, and a repository is a collection of images—sort of like a GitHub repository, except the code is already built. An account on a registry can create many repositories. The docker CLI uses Docker’s public registry by default. Note: We use Docker’s public registry here just because it’s free and pre-configured, but there are many public ones to choose from, and you can even set up your own private registry using Docker Trusted Registry. Log in with your Docker IDIf you don’t have a Docker account, sign up for one at cloud.docker.com. Make note of your username. Log in to the Docker public registry on your local machine. $ docker login Tag the imageThe notation for associating a local image with a repository on a registry is username/repository:tag. The tag is optional, but recommended, since it is the mechanism that registries use to give Docker images a version. Give the repository and tag meaningful names for the context, such as get-started:part2. This puts the image in the get-started repository and tag it as part2. Now, put it all together to tag the image. Run docker tag image with your username, repository, and tag names so that the image uploads to your desired destination. The syntax of the command is: docker tag image username/repository:tag For example: docker tag friendlyhello john/get-started:part2 Publish the imageUpload your tagged image to the repository: docker push username/repository:tag Once complete, the results of this upload are publicly available. If you log in to Docker Hub, you see the new image there, with its pull command. Pull and run the image from the remote repositoryFrom now on, you can use docker run and run your app on any machine with this command: docker run -p 4000:80 username/repository:tag If the image isn’t available locally on the machine, Docker pulls it from the repository. $ docker run -p 4000:80 john/get-started:part2 Unable to find image ‘john/get-started:part2’ locallypart2: Pulling from john/get-started10a267c67f42: Already existsf68a39a6a5e4: Already exists9beaffc0cf19: Already exists3c1fe835fb6b: Already exists4c9f1fa8fcb8: Already existsee7d8f576a14: Already existsfbccdcced46e: Already existsDigest: sha256:0601c866aab2adcc6498200efd0f754037e909e5fd42069adeff72d1e2439068Status: Downloaded newer image for john/get-started:part2 Running on http://0.0.0.0:80/ (Press CTRL+C to quit) No matter where docker run executes, it pulls your image, along with Python and all the dependencies from requirements.txt, and runs your code. It all travels together in a neat little package, and you don’t need to install anything on the host machine for Docker to run it. Here is a list of the basic Docker commands from this page, and some related ones if you’d like to explore a bit before moving on. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# Create image using this directory&apos;s Dockerfiledocker build -t friendlyhello .# Run &quot;friendlyname&quot; mapping port 4000 to 80docker run -p 4000:80 friendlyhello# Same thing, but in detached modedocker run -d -p 4000:80 friendlyhello# List all running containersdocker container ls# List all containers, even those not runningdocker container ls -a# Gracefully stop the specified containerdocker container stop &lt;hash&gt;# Force shutdown of the specified containerdocker container kill &lt;hash&gt;# Remove specified container from this machinedocker container rm &lt;hash&gt;# Remove all containersdocker container rm \$(docker container ls -a -q)# List all images on this machinedocker image ls -a# Remove specified image from this machinedocker image rm &lt;image id&gt;# Remove all images from this machinedocker image rm $(docker image ls -a -q)# Log in this CLI session using your Docker credentialsdocker login# Tag &lt;image&gt; for upload to registrydocker tag &lt;image&gt; username/repository:tag# Upload tagged image to registrydocker push username/repository:tag# Run image from a regdocker run username/repository:tag ReferencesA Docker Tutorial for BeginnersDocker TutorialDockerfile referenceDocs Docker - Get Started]]></content>
      <categories>
        <category>Technology</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Tutorial (1) -- Introduction]]></title>
    <url>%2F2018%2F02%2F15%2FDocker-Tutorial%2F</url>
    <content type="text"><![CDATA[What is Docker?Wikipedia defines Docker as an open-source project that automates the deployment of software applications inside containers by providing an additional layer of abstraction and automation of OS-level virtualization on Linux. Why Docker?Environment is essential for running software and it’s inconvenient to set up the same environment on different devices. Virtual machine could solve the above problem by creating an isolated operating system as the environment. However, virtual machine has disadvantages, such as consuming resources, creating redundant steps and slow initialization. While Docker utilizes the virtualization technology in the Linux kernel, it does not create virtual machines. Until a few releases ago, running Docker on OSX and Windows was quite a hassle. Lately however, Docker has invested significantly into improving the on-boarding experience for its users on these OSes, thus running Docker now is a cakewalk. The getting started guide on Docker has detailed instructions for setting up Docker on Mac, Linux and Windows. Once you are done installing Docker, test your Docker installation by running the following: 12345678910111213141516171819##List Docker CLI commandsdockerdocker container --help## Display Docker version and infodocker --versiondocker versiondocker info## Excecute Docker imagedocker run hello-world## List Docker imagesdocker image ls## List Docker containers (running, all, all in quiet mode)docker container lsdocker container ls -alldocker container ls -a -q Docker Example(Busybox)To get started, let’s run the following in our terminal: $ docker pull busybox The pull command fetches the busybox image from the Docker registry and saves it to our system. You can use the docker images command to see a list of all images on your system. $ docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE busybox latest c51f86c28340 4 weeks ago 1.109 MB Docker RunLet’s now run a Docker container based on this image. $ docker run busybox The docker ps command shows you all containers that are currently running. $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES Before we move ahead though, let’s quickly talk about deleting containers. To do that, you can run the docker rm command. $ docker rm 305297d7a235 ff0a5c3750b9 On deletion, you should see the IDs echoed back to you. If you have a bunch of containers to delete in one go, copy-pasting IDs can be tedious. In that case, you can simply run: \$ docker rm $(docker ps -a -q -f status=exited) This command deletes all containers that have a status of exited. In case you’re wondering, the -q flag, only returns the numeric IDs and -f filters output based on conditions provided. One last thing that’ll be useful is the –rm flag that can be passed to docker run which automatically deletes the container once it’s exited from. For one off docker runs, –rm flag is very useful. Lastly, you can also delete images that you no longer need by running docker rmi. TerminologyIn the last section, we used a lot of Docker-specific jargon which might be confusing to some. So before we go further, let me clarify some terminology that is used frequently in the Docker ecosystem. Containers - Created from Docker images and run the actual application. We create a container using docker run which we did using the busybox image that we downloaded. A list of running containers can be seen using the docker ps command. Docker Client - The command line tool that allows the user to interact with the daemon. More generally, there can be other forms of clients too - such as Kitematic which provide a GUI to the users. Docker Daemon - The background service running on the host that manages building, running and distributing Docker containers. The daemon is the process that runs in the operating system to which clients talk to. Dockerfile - A Dockerfile is a text document that contains all the commands you would normally execute manually in order to build a Docker image. Docker can build images automatically by reading the instructions from a Dockerfile. Docker Hub - A registry of Docker images. You can think of the registry as a directory of all available Docker images. If required, one can host their own Docker registries and can use them for pulling images. Images - Docker images are the basis of containers. An Image is an ordered collection of root filesystem changes and the corresponding execution parameters for use within a container runtime. An image typically contains a union of layered filesystems stacked on top of each other. An image does not have state and it never changes. Node - A node is a physical or virtual machine running an instance of the Docker Engine in swarm mode. Manager nodes perform swarm management and - orchestration duties. By default manager nodes are also worker nodes. Worker nodes execute tasks. Registry - A Registry is a hosted service containing repositories of images which responds to the Registry API. The default registry can be accessed using a browser at Docker Hub or using the docker search command. Repository - A repository is a set of Docker images. A repository can be shared by pushing it to a registry server. The different images in the repository can be labeled using tags. Service - A service is the definition of how you want to run your application containers in a swarm. At the most basic level a service defines which container image to run in the swarm and which commands to run in the container. For orchestration purposes, the service defines the “desired state”, meaning how many containers to run as tasks and constraints for deploying the containers. Stack - A stack is a group of interrelated services that share dependencies, and can be orchestrated and scaled together. A single stack is capable of defining and coordinating the functionality of an entire application (though very complex applications may want to use multiple stacks). Swarm - A swarm is a cluster of one or more Docker Engines running in swarm mode. Tag - A tag is a label applied to a Docker image in a repository. Tags are how various images in a repository are distinguished from each other. ReferencesA Docker Tutorial for BeginnersDocker TutorialDockerfile referenceDocs Docker - Get Started]]></content>
      <categories>
        <category>Technology</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DevOps Introduction]]></title>
    <url>%2F2018%2F02%2F15%2FDevOps-Introduction%2F</url>
    <content type="text"><![CDATA[DefinitionDevOps is a set of practices intended to reduce the time between committing a change to a system and the change being placed into normal production, while ensuring high quality. DevOps toolchain Code — code development and review, source code management tools, code merging Build — continuous integration tools, build status Test — continuous testing tools that provide feedback on business risks Package — artifact repository, application pre-deployment staging Release — change management, release approvals, release automation Configure — infrastructure configuration and management, Infrastructure as Code tools Monitor — applications performance monitoring, end–user experience Why DevOpsThe Water-fall model worked fine and served well for many years however it had some challenges. In the following diagram the challenges of Waterfall Model are highlighted. In the above diagram you can see that both Development and Operations had challenges in the Waterfall Model. From Developers point of view there were majorly two challenges: After Development, the code deployment time was huge. Pressure of work on old, pending and new code was high because development and deployment time was high. On the other hand, Operations was also not completely satisfied. There were four major challenges they faced as per the above diagram: It was difficult to maintain ~100% uptime of the production environment. Infrastructure Automation tools were not very affective. Number of severs to be monitored keeps on increasing with time and hence the complexity. It was very difficult to provide feedback and diagnose issue in the product. In the following diagram proposed solution to the challenges of Waterfall Model are highlighted. In the above diagram, Probable Solutions for the issues faced by Developers and Operations are highlighted in blue. This sets the guidelines for an Ideal Software Development strategy. From Developers point of view: A system which enables code deployment without any delay or wait time. A system where work happens on the current code itself i.e. development sprints are short and well planned. From Operations point of view: System should have at-least 99% uptime. Tools &amp; systems are there in place for easy administration. Effective monitoring and feedbacks system should be there. Better Collaboration between Development &amp; Operations and is common requirement for Developers and Operations team. ReferencesDevOps - WikipediaDevOps Tutorial : Introduction To DevOpsWhat Is DevOps?]]></content>
      <categories>
        <category>software development</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scrum Introduction]]></title>
    <url>%2F2018%2F02%2F14%2FScrum-Introduction%2F</url>
    <content type="text"><![CDATA[Definition of ScrumScrum (n): A framework within which people can address complex adaptive problems, while productively and creatively delivering products of the highest possible value. Scrum is:• Lightweight• Simple to understand• Difficult to master Uses of Scrum Research and identify viable markets, technologies, and product capabilities; Develop products and enhancements; Release products and enhancements, as frequently as many times per day; Develop and sustain Cloud (online, secure, on-demand) and other operationalenvironments for product use; and, Sustain and renew products. Scrum TheoryScrum is founded on empirical process control theory, or empiricism. Empiricism asserts that knowledge comes from experience and making decisions based on what is known. Scrum employs an iterative, incremental approach to optimize predictability and control risk. Three pillars uphold every implementation of empirical process control:transparency, inspection, and adaptation. TransparencySignificant aspects of the process must be visible to those responsible for the outcome. Transparency requires those aspects be defined by a common standard so observers share a common understanding of what is being seen. For example: • A common language referring to the process must be shared by all participants; and,• Those performing the work and those inspecting the resulting increment must share a common definition of “Done”. InspectionScrum users must frequently inspect Scrum artifacts and progress toward a Sprint Goal to detect undesirable variances. Their inspection should not be so frequent that inspection gets in the way of the work. Inspections are most beneficial when diligently performed by skilled inspectors at the point of work. AdaptationIf an inspector determines that one or more aspects of a process deviate outside acceptable limits, and that the resulting product will be unacceptable, the process or the material being processed must be adjusted. An adjustment must be made as soon as possible to minimize further deviation. Scrum prescribes four formal events for inspection and adaptation, as described in the Scrum Events section of this document: • Sprint Planning• Daily Scrum• Sprint Review• Sprint Retrospective The Scrum TeamThe Scrum Team consists of a Product Owner, the Development Team, and a Scrum Master. Scrum Teams are self-organizing and cross-functional. Self-organizing teams choose how best to accomplish their work, rather than being directed by others outside the team. Cross-functional teams have all competencies needed to accomplish the work without depending on others not part of the team. The team model in Scrum is designed to optimize flexibility, creativity, and productivity. The Product OwnerThe Product Owner is responsible for maximizing the value of the product resulting from work of the Development Team. How this is done may vary widely across organizations, Scrum Teams, and individuals. The Product Owner is the sole person responsible for managing the Product Backlog. Product Backlog management includes: • Clearly expressing Product Backlog items;• Ordering the items in the Product Backlog to best achieve goals and missions;• Optimizing the value of the work the Development Team performs;• Ensuring that the Product Backlog is visible, transparent, and clear to all, and shows what the Scrum Team will work on next;• Ensuring the Development Team understands items in the Product Backlog to the level needed. The Product Owner may do the above work, or have the Development Team do it. However, the Product Owner remains accountable. The Product Owner is one person, not a committee. The Product Owner may represent the desires of a committee in the Product Backlog, but those wanting to change a Product Backlog item’s priority must address the Product Owner. For the Product Owner to succeed, the entire organization must respect his or her decisions. The Product Owner’s decisions are visible in the content and ordering of the Product Backlog. No one can force the Development Team to work from a different set of requirements. The Development TeamThe Development Team consists of professionals who do the work of delivering a potentially releasable Increment of “Done” product at the end of each Sprint. A “Done” increment is required at the Sprint Review. Only members of the Development Team create the Increment. Development Teams are structured and empowered by the organization to organize and manage their own work. The resulting synergy optimizes the Development Team’s overall efficiency and effectiveness. Development Teams have the following characteristics: • They are self-organizing. No one (not even the Scrum Master) tells the Development Team how to turn Product Backlog into Increments of potentially releasable functionality;• Development Teams are cross-functional, with all the skills as a team necessary to create a product Increment;• Scrum recognizes no titles for Development Team members, regardless of the work being performed by the person;• Scrum recognizes no sub-teams in the Development Team, regardless of domains that need to be addressed like testing, architecture, operations, or business analysis;• Individual Development Team members may have specialized skills and areas of focus, but accountability belongs to the Development Team as a whole. Development Team SizeOptimal Development Team size is small enough to remain nimble and large enough to complete significant work within a Sprint. Fewer than three Development Team members decrease interaction and results in smaller productivity gains. Smaller Development Teams may encounter skill constraints during the Sprint, causing the Development Team to be unable to deliver a potentially releasable Increment. Having more than nine members requires too much coordination. Large Development Teams generate too much complexity for an empirical process to be useful. The Product Owner and Scrum Master roles are not included in this count unless they are also executing the work of the Sprint Backlog. The Scrum MasterThe Scrum Master is responsible for promoting and supporting Scrum as defined in the Scrum Guide. Scrum Masters do this by helping everyone understand Scrum theory, practices, rules, and values. The Scrum Master is a servant-leader for the Scrum Team. The Scrum Master helps those outside the Scrum Team understand which of their interactions with the Scrum Team are helpful and which aren’t. The Scrum Master helps everyone change these interactions to maximize the value created by the Scrum Team. Scrum Master Service to the Product OwnerThe Scrum Master serves the Product Owner in several ways, including:• Ensuring that goals, scope, and product domain are understood by everyone on the ScrumTeam as well as possible;• Finding techniques for effective Product Backlog management;• Helping the Scrum Team understand the need for clear and concise Product Backlog items;• Understanding product planning in an empirical environment;• Ensuring the Product Owner knows how to arrange the Product Backlog to maximize value;• Understanding and practicing agility;• Facilitating Scrum events as requested or needed. Scrum Master Service to the Development TeamThe Scrum Master serves the Development Team in several ways, including:• Coaching the Development Team in self-organization and cross-functionality;• Helping the Development Team to create high-value products;• Removing impediments to the Development Team’s progress;• Facilitating Scrum events as requested or needed;• Coaching the Development Team in organizational environments in which Scrum is not yet fully adopted and understood. Scrum Master Service to the OrganizationThe Scrum Master serves the organization in several ways, including:• Leading and coaching the organization in its Scrum adoption;• Planning Scrum implementations within the organization;• Helping employees and stakeholders understand and enact Scrum and empirical productdevelopment;• Causing change that increases the productivity of the Scrum Team;• Working with other Scrum Masters to increase the effectiveness of the application of Scrum in the organization. Scrum EventsPrescribed events are used in Scrum to create regularity and to minimize the need for meetings not defined in Scrum. All events are time-boxed events, such that every event has a maximum duration. Once a Sprint begins, its duration is fixed and cannot be shortened or lengthened. The remaining events may end whenever the purpose of the event is achieved, ensuring an appropriate amount of time is spent without allowing waste in the process. The Scrum Events are: Sprint Sprint Planning Daily Scrum Sprint Review Sprint Retrospective The SprintThe heart of Scrum is a Sprint, a time-box of one month or less during which a “Done”, useable, and potentially releasable product Increment is created. Sprints have consistent durations throughout a development effort. A new Sprint starts immediately after the conclusion of theprevious Sprint. During the Sprint:• No changes are made that would endanger the Sprint Goal;• Quality goals do not decrease;• Scope may be clarified and re-negotiated between the Product Owner and Development Team as more is learned. Each Sprint may be considered a project with no more than a one-month horizon. Like projects, Sprints are used to accomplish something. Each Sprint has a goal of what is to be built, a design and flexible plan that will guide building it, the work, and the resultant product increment. Sprints are limited to one calendar month. When a Sprint’s horizon is too long the definition of what is being built may change, complexity may rise, and risk may increase. Sprints enable predictability by ensuring inspection and adaptation of progress toward a Sprint Goal at least every calendar month. Sprints also limit risk to one calendar month of cost. Sprint PlanningThe work to be performed in the Sprint is planned at the Sprint Planning. This plan is created by the collaborative work of the entire Scrum Team. Sprint Planning is time-boxed to a maximum of eight hours for a one-month Sprint. For shorter Sprints, the event is usually shorter. The Scrum Master ensures that the event takes place and that attendants understand its purpose. The Scrum Master teaches the Scrum Team to keep it within the time-box. Sprint Planning answers the following:• What can be delivered in the Increment resulting from the upcoming Sprint?• How will the work needed to deliver the Increment be achieved? Topic One: What can be done this Sprint?The Development Team works to forecast the functionality that will be developed during the Sprint. The Product Owner discusses the objective that the Sprint should achieve and the Product Backlog items that, if completed in the Sprint, would achieve the Sprint Goal. The entire Scrum Team collaborates on understanding the work of the Sprint. Topic Two: How will the chosen work get done?Having set the Sprint Goal and selected the Product Backlog items for the Sprint, the Development Team decides how it will build this functionality into a “Done” product Increment during the Sprint. The Product Backlog items selected for this Sprint plus the plan for delivering them is called the Sprint Backlog. By the end of the Sprint Planning, the Development Team should be able to explain to the Product Owner and Scrum Master how it intends to work as a self-organizing team to accomplish the Sprint Goal and create the anticipated Increment. Sprint GoalThe Sprint Goal is an objective set for the Sprint that can be met through the implementation of Product Backlog. It provides guidance to the Development Team on why it is building the Increment. It is created during the Sprint Planning meeting. The Sprint Goal gives the Development Team some flexibility regarding the functionality implemented within the Sprint. Daily ScrumThe Daily Scrum is a 15-minute time-boxed event for the Development Team. The Daily Scrum is held every day of the Sprint. At it, the Development Team plans work for the next 24 hours. This optimizes team collaboration and performance by inspecting the work since the last Daily Scrum and forecasting upcoming Sprint work. The Daily Scrum is held at the same time and place each day to reduce complexity. Sprint ReviewA Sprint Review is held at the end of the Sprint to inspect the Increment and adapt the Product Backlog if needed. During the Sprint Review, the Scrum Team and stakeholders collaborate about what was done in the Sprint. The Sprint Review includes the following elements:• Attendees include the Scrum Team and key stakeholders invited by the Product Owner;• The Product Owner explains what Product Backlog items have been “Done” and what has not been “Done”;• The Development Team discusses what went well during the Sprint, what problems it ran into, and how those problems were solved;• The Development Team demonstrates the work that it has “Done” and answers questions about the Increment;• The Product Owner discusses the Product Backlog as it stands. He or she projects likely target and delivery dates based on progress to date (if needed);• The entire group collaborates on what to do next, so that the Sprint Review provides valuable input to subsequent Sprint Planning;• Review of how the marketplace or potential use of the product might have changed what is the most valuable thing to do next;• Review of the timeline, budget, potential capabilities, and marketplace for the next anticipated releases of functionality or capability of the product. The result of the Sprint Review is a revised Product Backlog that defines the probable ProductBacklog items for the next Sprint. The Product Backlog may also be adjusted overall to meet newopportunities. Sprint RetrospectiveThe Sprint Retrospective is an opportunity for the Scrum Team to inspect itself and create a plan for improvements to be enacted during the next Sprint. The purpose of the Sprint Retrospective is to:• Inspect how the last Sprint went with regards to people, relationships, process, and tools;• Identify and order the major items that went well and potential improvements;• Create a plan for implementing improvements to the way the Scrum Team does its work. Scrum ArtifactsScrum’s artifacts represent work or value to provide transparency and opportunities for inspection and adaptation. Artifacts defined by Scrum are specifically designed to maximize transparency of key information so that everybody has the same understanding of the artifact. The Scrum Artifacts are: Product Backlog Sprint Backlog Increment Referenceswhat-is-scrum2017-Scrum-Guide]]></content>
      <categories>
        <category>software development</category>
      </categories>
      <tags>
        <tag>Scrum</tag>
        <tag>Agile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LINQ Tutorial]]></title>
    <url>%2F2018%2F02%2F14%2FLINQ%2F</url>
    <content type="text"><![CDATA[OverviewLanguage Integrated Query (LINQ, pronounced “link”) is a Microsoft .NET Framework component that adds native data querying capabilities to .NET languages. All LINQ query operations consist of three distinct actions: Obtain the data source. Create the query. Execute the query. The following example shows how the three parts of a query operation are expressed in source code:12345678910111213141516171819202122class IntroToLINQ&#123; static void Main() &#123; // The Three Parts of a LINQ Query: // 1. Data source. int[] numbers = new int[7] &#123; 0, 1, 2, 3, 4, 5, 6 &#125;; // 2. Query creation. // numQuery is an IEnumerable&lt;int&gt; var numQuery = from num in numbers where (num % 2) == 0 select num; // 3. Query execution. foreach (int num in numQuery) &#123; Console.Write("&#123;0,1&#125; ", num); &#125; &#125;&#125; The following illustration shows the complete query operation. In LINQ the execution of the query is distinct from the query itself; in other words you have not retrieved any data just by creating a query variable. Why LINQIn terms of why we should use LINQ, we can explain it by an example: to find a student object in a student array. Before C# 2.0, we could find specific object in array only by using like “foreach” or “for”. For example: 1234567891011121314151617181920212223242526272829303132333435class Student&#123;public int StudentID &#123; get; set; &#125;public String StudentName &#123; get; set; &#125;public int Age &#123; get; set; &#125;&#125;class Program&#123; static void Main(string[] args) &#123; Student[] studentArray = &#123; new Student() &#123; StudentID = 1, StudentName = "John", Age = 18 &#125;, new Student() &#123; StudentID = 2, StudentName = "Steve", Age = 21 &#125;, new Student() &#123; StudentID = 3, StudentName = "Bill", Age = 25 &#125;, new Student() &#123; StudentID = 4, StudentName = "Ram" , Age = 20 &#125;, new Student() &#123; StudentID = 5, StudentName = "Ron" , Age = 31 &#125;, new Student() &#123; StudentID = 6, StudentName = "Chris", Age = 17 &#125;, new Student() &#123; StudentID = 7, StudentName = "Rob",Age = 19 &#125;, &#125;; Student[] students = new Student[10]; int i = 0; foreach (Student std in studentArray) &#123; if (std.Age &gt; 12 &amp;&amp; std.Age &lt; 20) &#123; students[i] = std; i++; &#125; &#125; &#125;&#125; To increase readability and maintainability, in C# 2.0 delegate was imported:123456789101112131415161718192021222324252627282930313233343536373839delegate bool FindStudent(Student std);class StudentExtension&#123; public static Student[] where(Student[] stdArray, FindStudent del) &#123; int i=0; Student[] result = new Student[10]; foreach (Student std in stdArray) if (del(std)) &#123; result[i] = std; i++; &#125; return result; &#125;&#125; class Program &#123; static void Main(string[] args) &#123; Student[] studentArray = &#123; new Student() &#123; StudentID = 1, StudentName = "John", Age = 18 &#125; , new Student() &#123; StudentID = 2, StudentName = "Steve", Age = 21 &#125; , new Student() &#123; StudentID = 3, StudentName = "Bill", Age = 25 &#125; , new Student() &#123; StudentID = 4, StudentName = "Ram" , Age = 20 &#125; , new Student() &#123; StudentID = 5, StudentName = "Ron" , Age = 31 &#125; , new Student() &#123; StudentID = 6, StudentName = "Chris", Age = 17 &#125; , new Student() &#123; StudentID = 7, StudentName = "Rob",Age = 19 &#125; , &#125;; Student[] students = StudentExtension.where(studentArray, delegate(Student std)&#123; return std.Age &gt; 12 &amp;&amp; std.Age &lt; 20; &#125;); &#125; &#125;&#125; Thus, if we want to find students with different names, we can reuse the delegate instead of using different for-loop. However, C# code could be more compact and readable. LINQ was imported in C# 3.0. For example:123456789101112131415161718192021222324class Program&#123; static void Main(string[] args) &#123; Student[] studentArray = &#123; new Student() &#123; StudentID = 1, StudentName = "John", age = 18 &#125; , new Student() &#123; StudentID = 2, StudentName = "Steve", age = 21 &#125; , new Student() &#123; StudentID = 3, StudentName = "Bill", age = 25 &#125; , new Student() &#123; StudentID = 4, StudentName = "Ram" , age = 20 &#125; , new Student() &#123; StudentID = 5, StudentName = "Ron" , age = 31 &#125; , new Student() &#123; StudentID = 6, StudentName = "Chris", age = 17 &#125; , new Student() &#123; StudentID = 7, StudentName = "Rob",age = 19 &#125; , &#125;; // Use LINQ to find teenager students Student[] teenAgerStudents = studentArray.Where(s =&gt; s.age &gt; 12 &amp;&amp; s.age &lt; 20).ToArray(); // Use LINQ to find first student whose name is Bill Student bill = studentArray.Where(s =&gt; s.StudentName == "Bill").FirstOrDefault(); // Use LINQ to find student whose StudentID is 5 Student student5 = studentArray.Where(s =&gt; s.StudentID == 5).FirstOrDefault(); &#125;&#125; Syntax of LINQThere are two syntaxes of LINQ. These are the following ones. Lamda (Method) Syntax12var longWords = words.Where( w ⇒ w.length &gt; 10);Dim longWords = words.Where(Function(w) w.length &gt; 10) Query (Comprehension) Syntax12var longwords = from w in words where w.length &gt; 10;Dim longwords = from w in words where w.length &gt; 10 Types of LINQThe types of LINQ are mentioned below in brief. LINQ to Objects LINQ to XML(XLINQ) LINQ to DataSet LINQ to SQL (DLINQ) LINQ to Entities Walkthrough: Writing Queries in C# (LINQ)This walkthrough demonstrates the C# language features that are used to write LINQ query expressions. Create a C# ProjectTo create a project in Visual Studio Start Visual Studio. On the menu bar, choose File, New, Project.The New Project dialog box opens. Expand Installed, expand Templates, expand Visual C#, and then choose Console Application. In the Name text box, enter a different name or accept the default name, and then choose the OK button.The new project appears in Solution Explorer. Notice that your project has a reference to System.Core.dll and a using directive for the System.Linq namespace. Create an in-Memory Data Source To add the data sourceAdd the Student class and the initialized list of students to the Program class in your project. 123456789101112131415public class Student&#123; public string First &#123; get; set; &#125; public string Last &#123; get; set; &#125; public int ID &#123; get; set; &#125; public List&lt;int&gt; Scores;&#125;// Create a data source by using a collection initializer.static List&lt;Student&gt; students = new List&lt;Student&gt;&#123; new Student &#123;First="Svetlana", Last="Omelchenko", ID=111, Scores= new List&lt;int&gt; &#123;97, 92, 81, 60&#125;&#125;, new Student &#123;First="Claire", Last="O'Donnell", ID=112, Scores= new List&lt;int&gt; &#123;75, 84, 91, 39&#125;&#125;, new Student &#123;First="Sven", Last="Mortensen", ID=113, Scores= new List&lt;int&gt; &#123;88, 94, 65, 91&#125;&#125;,&#125;; To add a new Student to the Students listAdd a new Student to the Students list and use a name and test scores of your choice. Try typing all the new student information in order to better learn the syntax for the object initializer. Create the Query To create a simple queryIn the application’s Main method, create a simple query that, when it is executed, will produce a list of all students whose score on the first test was greater than 90.123456// Create the query.// The first line could also be written as "var studentQuery ="IEnumerable&lt;Student&gt; studentQuery = from student in students where student.Scores[0] &gt; 90 select student; Execute the Query To execute the query Now write the foreach loop that will cause the query to execute. Note the following about the code: Each element in the returned sequence is accessed through the iteration variable in the foreach loop. The type of this variable is Student, and the type of the query variable is compatible, IEnumerable. After you have added this code, build and run the application to see the results in the Console window. 123456// Execute the query.// var could be used here also.foreach (Student student in studentQuery)&#123; Console.WriteLine("&#123;0&#125;, &#123;1&#125;", student.Last, student.First);&#125; To add another filter conditionYou can combine multiple Boolean conditions in the where clause in order to further refine a query. 1where student.Scores[0] &gt; 90 &amp;&amp; student.Scores[3] &lt; 80 Modify the QueryTo order the resultsYou can order the returned sequence by any accessible field in the source elements.1orderby student.Last ascending To group the results Grouping is a powerful capability in query expressions. A query with a group clause produces a sequence of groups, and each group itself contains a Key and a sequence that consists of all the members of that group.The following new query groups the students by using the first letter of their last name as the key. 1234// studentQuery2 is an IEnumerable&lt;IGrouping&lt;char, Student&gt;&gt;var studentQuery2 = from student in students group student by student.Last[0]; Note that the type of the query has now changed. It now produces a sequence of groups that have a char type as a key, and a sequence of Student objects. 12345678910// studentGroup is a IGrouping&lt;char, Student&gt;foreach (var studentGroup in studentQuery2)&#123; Console.WriteLine(studentGroup.Key); foreach (Student student in studentGroup) &#123; Console.WriteLine(" &#123;0&#125;, &#123;1&#125;", student.Last, student.First); &#125;&#125; To make the variables implicitly typedYou can write the same query and foreach loop much more conveniently by using var. The var keyword does not change the types of your objects; it just instructs the compiler to infer the types.Note that in the inner foreach loop, the iteration variable is still typed as Student, and the query works just as before.12345678910111213var studentQuery3 = from student in students group student by student.Last[0];foreach (var groupOfStudents in studentQuery3)&#123; Console.WriteLine(groupOfStudents.Key); foreach (var student in groupOfStudents) &#123; Console.WriteLine(" &#123;0&#125;, &#123;1&#125;", student.Last, student.First); &#125;&#125; To order the groups by their key valueWhen you run the previous query, you notice that the groups are not in alphabetical order. To change this, you must provide an orderby clause after the group clause.But to use an orderby clause, you first need an identifier that serves as a reference to the groups created by the group clause. You provide the identifier by using the into keyword, as follows:123456789101112131415var studentQuery4 = from student in students group student by student.Last[0] into studentGroup orderby studentGroup.Key select studentGroup;foreach (var groupOfStudents in studentQuery4)&#123; Console.WriteLine(groupOfStudents.Key); foreach (var student in groupOfStudents) &#123; Console.WriteLine(" &#123;0&#125;, &#123;1&#125;", student.Last, student.First); &#125;&#125; To introduce an identifier by using letYou can use the let keyword to introduce an identifier for any expression result in the query expression. This identifier can be a convenience, as in the following example, or it can enhance performance by storing the results of an expression so that it does not have to be calculated multiple times.123456789101112131415// studentQuery5 is an IEnumerable&lt;string&gt;// This query returns those students whose// first test score was higher than their// average score.var studentQuery5 = from student in students let totalScore = student.Scores[0] + student.Scores[1] + student.Scores[2] + student.Scores[3] where totalScore / 4 &lt; student.Scores[0] select student.Last + " " + student.First;foreach (string s in studentQuery5)&#123; Console.WriteLine(s);&#125; To use method syntax in a query expressionThe following code calculates the total score for each Student in the source sequence, and then calls the Average() method on the results of that query to calculate the average score of the class.1234567891011var studentQuery6 = from student in students let totalScore = student.Scores[0] + student.Scores[1] + student.Scores[2] + student.Scores[3] select totalScore;double averageScore = studentQuery6.Average();Console.WriteLine("Class average score = &#123;0&#125;", averageScore);// Output:// Class average score = 334.166666666667 To transform or project in the select clause It is very common for a query to produce a sequence whose elements differ from the elements in the source sequences. Delete or comment out your previous query and execution loop, and replace it with the following code. Note that the query returns a sequence of strings (not Students), and this fact is reflected in the foreach loop. 12345678910IEnumerable&lt;string&gt; studentQuery7 = from student in students where student.Last == "Garcia" select student.First;Console.WriteLine("The Garcias in the class are:");foreach (string s in studentQuery7)&#123; Console.WriteLine(s);&#125; Code earlier in this walkthrough indicated that the average class score is approximately 334. To produce a sequence of Students whose total score is greater than the class average, together with their Student ID, you can use an anonymous type in the select statement: 1234567891011var studentQuery8 = from student in students let x = student.Scores[0] + student.Scores[1] + student.Scores[2] + student.Scores[3] where x &gt; averageScore select new &#123; id = student.ID, score = x &#125;;foreach (var item in studentQuery8)&#123; Console.WriteLine("Student ID: &#123;0&#125;, Score: &#123;1&#125;", item.id, item.score);&#125; ReferencesLanguage Integrated QueryLINQ FundamentalLINQ TutorialGetting Started with LINQ in C#]]></content>
      <categories>
        <category>Technology</category>
      </categories>
      <tags>
        <tag>LINQ</tag>
        <tag>C#</tag>
        <tag>ASP.NET</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WebSocket Tutorial]]></title>
    <url>%2F2018%2F02%2F12%2FWebSocket%2F</url>
    <content type="text"><![CDATA[Why WebSocketMany people might have the doubt, why do we need WebSocket when we already have HTTP protocal. The answer is simple: with HTTP communication could only be initiated by client. For example, if we want to know about the weather today, we can only send request from client to server, then the server responses with the search result. It’s not applicable for server to push information to client automatically. Under the condition that client need the real-time status of server, it would be difficult for traditional HTTP protocal to achieve that. One commonly used solution is called polling. But polling is inefficient which creates a large amount of requests. Thus, WebSocket is created to solve the problem above. OverviewWeb Sockets is a next-generation bidirectional communication technology for web applications which operates over a single socket and is exposed via a JavaScript interface in HTML 5 compliant browsers. Once you get a Web Socket connection with the web server, you can send data from browser to server by calling a send() method, and receive data from server to browser by an onmessage event handler. Following is the API which creates a new WebSocket object. 1var Socket = new WebSocket(url, [protocal] ); Here first argument, url, specifies the URL to which to connect. The second attribute, protocol is optional, and if present, specifies a sub-protocol that the server must support for the connection to be successful. WebSocket AttributesFollowing are the attribute of WebSocket object. Assuming we created Socket object as mentioned above − Attribute Description Socket.readyState The readonly attribute readyState represents the state of the connection. It can have the following values:A value of 0 indicates that the connection has not yet been established.A value of 1 indicates that the connection is established and communication is possible. A value of 2 indicates that the connection is going through the closing handshake. A value of 3 indicates that the connection has been closed or could not be opened. Socket.bufferedAmount The readonly attribute bufferedAmount represents the number of bytes of UTF-8 text that have been queued using send() method. WebSocket EventsFollowing are the events associated with WebSocket object. Assuming we created Socket object as mentioned above: Event Event Handler Description open Socket.onopen This event occurs when socket connection is established. message Socket.onmessage This event occurs when client receives data from server. error Socket.onerror This event occurs when there is any error in communication. close Socket.onclose This event occurs when connection is closed. WebSocket MethodsFollowing are the methods associated with WebSocket object. Assuming we created Socket object as mentioned above: Method Description Socket.send() The send(data) method transmits data using the connection. Socket.close() The close() method would be used to terminate any existing connection. WebSocket ExampleA WebSocket is a standard bidirectional TCP socket between the client and the server. The socket starts out as a HTTP connection and then “Upgrades” to a TCP socket after a HTTP handshake. After the handshake, either side can send data. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;!DOCTYPE HTML&gt;&lt;html&gt;&lt;head&gt;&lt;script type="text/javascript"&gt;function WebSocketTest()&#123;if ("WebSocket" in window)&#123;alert("WebSocket is supported by your Browser!");// Let us open a web socketvar ws = new WebSocket("ws://localhost:9998/echo");ws.onopen = function()&#123;// Web Socket is connected, send data using send()ws.send("Message to send");alert("Message is sent...");&#125;;ws.onmessage = function (evt)&#123;var received_msg = evt.data;alert("Message is received...");&#125;;ws.onclose = function()&#123;// websocket is closed.alert("Connection is closed...");&#125;;window.onbeforeunload = function(event) &#123;socket.close();&#125;;&#125;else&#123;// The browser doesn't support WebSocketalert("WebSocket NOT supported by your Browser!");&#125;&#125;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;div id="sse"&gt;&lt;a href="javascript:WebSocketTest()"&gt;Run WebSocket&lt;/a&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; ReferencesIntroducing WebSockets: Bringing Sockets to the WebWebSockets - Send &amp; Receive MessagesHTML5 - WebSocketsPush technologyWebSockets vs REST: Understanding the DifferenceWebSockets Tutorial]]></content>
      <categories>
        <category>Technology</category>
      </categories>
      <tags>
        <tag>WebSocket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Building a cat classifier with logistic regression from scratch]]></title>
    <url>%2F2018%2F02%2F09%2Fbuilding-a-cat-classifier-with-logistic-regression%2F</url>
    <content type="text"><![CDATA[GoalBuild the general architecture of a learning algorithm, including: Initializing parameters Calculating the cost function and its gradient Using an optimization algorithm (gradient descent) Gather all three functions above into a main model function, in the right order. PackagesFirst, let’s run the cell below to import all the packages. numpy is the fundamental package for scientific computing with Python. h5py is a common package to interact with a dataset that is stored on an H5 file. matplotlib is a famous library to plot graphs in Python. PIL and scipy are used here to test your model with your own picture at the end. 123456789import numpy as npimport matplotlib.pyplot as pltimport h5pyimport scipyfrom PIL import Imagefrom scipy import ndimagefrom lr_utils import load_dataset%matplotlib inline Overview of the Problem setThe dataset we will use contains: a training set of m_train images labeled as cat (y=1) or non-cat (y=0) a test set of m_test images labeled as cat or non-cat each image is of shape (num_px, num_px, 3) where 3 is for the 3 channels (RGB). Thus, each image is square (height = num_px) and (width = num_px). First we import the data from file 12# Loading the data (cat/non-cat)train_set_x_orig, train_set_y, test_set_x_orig, test_set_y Now we show information of data, each image is of shape (64, 64, 3) showing it’s 64*64, RGB. 12345678print ("Number of training examples: m_train = " + str(m_train))print ("Number of testing examples: m_test = " + str(m_test))print ("Height/Width of each image: num_px = " + str(num_px))print ("Each image is of size: (" + str(num_px) + ", " + str(num_px) + ", 3)")print ("train_set_x shape: " + str(train_set_x_orig.shape))print ("train_set_y shape: " + str(train_set_y.shape))print ("test_set_x shape: " + str(test_set_x_orig.shape))print ("test_set_y shape: " + str(test_set_y.shape)) Output:Number of training examples: m_train = 209Number of testing examples: m_test = 50Height/Width of each image: num_px = 64Each image is of size: (64, 64, 3)train_set_x shape: (209, 64, 64, 3)train_set_y shape: (1, 209)test_set_x shape: (50, 64, 64, 3)test_set_y shape: (1, 50) Then we reshape the training and test dataset to column vector:1234print ("train_set_x_flatten shape: " + str(train_set_x_flatten.shape))print ("train_set_y shape: " + str(train_set_y.shape))print ("test_set_x_flatten shape: " + str(test_set_x_flatten.shape))print ("test_set_y shape: " + str(test_set_y.shape)) Output:train_set_x_flatten shape: (12288, 209)train_set_y shape: (1, 209)test_set_x_flatten shape: (12288, 50)test_set_y shape: (1, 50) At last, let’s standardize our dataset:12train_set_x = train_set_x_flatten/255.test_set_x = test_set_x_flatten/255. Mathematical expression of the algorithm Step Initialize the parameters of the model Learn the parameters for the model by minimizing the cost Use the learned parameters to make predictions (on the test set) Analyse the results and conclude For one example $x^{(i)}$:$$z^{(i)} = w^T x^{(i)} + b \tag{1}$$$$\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})\tag{2}$$$$ \mathcal{L}(a^{(i)}, y^{(i)}) = - y^{(i)} \log(a^{(i)}) - (1-y^{(i)} ) \log(1-a^{(i)})\tag{3}$$ The cost is then computed by summing over all training examples:$$ J = \frac{1}{m} \sum_{i=1}^m \mathcal{L}(a^{(i)}, y^{(i)})\tag{6}$$ Building the parts of our algorithm StepThe main steps for building a Neural Network are: Define the model structure (such as number of input features) Initialize the model’s parameters Loop: Calculate current loss (forward propagation) Calculate current gradient (backward propagation) Update parameters (gradient descent) Forward and Backward propagationForward Propagation: You get X You compute $A = \sigma(w^T X + b) = (a^{(0)}, a^{(1)}, …, a^{(m-1)}, a^{(m)})$ You calculate the cost function: $J = -\frac{1}{m}\sum_{i=1}^{m}y^{(i)}\log(a^{(i)})+(1-y^{(i)})\log(1-a^{(i)})$ Here are the two formulas you will be using: $$ \frac{\partial J}{\partial w} = \frac{1}{m}X(A-Y)^T$$ $$ \frac{\partial J}{\partial b} = \frac{1}{m} \sum_{i=1}^m (a^{(i)}-y^{(i)})$$ Here is the Forward-propagation function:1234567891011121314151617181920212223242526272829303132333435def propagate(w, b, X, Y):"""Implement the cost function and its gradient for the propagation explained aboveArguments:w -- weights, a numpy array of size (num_px * num_px * 3, 1)b -- bias, a scalarX -- data of size (num_px * num_px * 3, number of examples)Y -- true "label" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples)Return:cost -- negative log-likelihood cost for logistic regressiondw -- gradient of the loss with respect to w, thus same shape as wdb -- gradient of the loss with respect to b, thus same shape as b"""m = X.shape[1]# FORWARD PROPAGATION (FROM X TO COST)# compute activation (1, number of examples)A = sigmoid(np.dot(w.T, X) + b)# compute costcost = -1.0/m * np.sum(Y*np.log(A) + (1-Y)*np.log(1-A))# BACKWARD PROPAGATION (TO FIND GRAD)# compute gradientdw = 1.0/m*np.dot(X, (A-Y).T)db = 1.0/m*np.sum(A-Y)cost = np.squeeze(cost)grads = &#123;"dw": dw,"db": db&#125;return grads, cost 12345w, b, X, Y = np.array([[1.],[2.]]), 2., np.array([[1.,2.,-1.],[3.,4.,-3.2]]), np.array([[1,0,1]])grads, cost = propagate(w, b, X, Y)print (&quot;dw = &quot; + str(grads[&quot;dw&quot;]))print (&quot;db = &quot; + str(grads[&quot;db&quot;]))print (&quot;cost = &quot; + str(cost)) Output:dw = [[ 0.99845601][ 2.39507239]]db = 0.00145557813678cost = 5.80154531939 Optimization123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):&quot;&quot;&quot;This function optimizes w and b by running a gradient descent algorithmArguments:w -- weights, a numpy array of size (num_px * num_px * 3, 1)b -- bias, a scalarX -- data of shape (num_px * num_px * 3, number of examples)Y -- true &quot;label&quot; vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples)num_iterations -- number of iterations of the optimization looplearning_rate -- learning rate of the gradient descent update ruleprint_cost -- True to print the loss every 100 stepsReturns:params -- dictionary containing the weights w and bias bgrads -- dictionary containing the gradients of the weights and bias with respect to the cost functioncosts -- list of all the costs computed during the optimization, this will be used to plot the learning curve.Tips:1) Calculate the cost and the gradient for the current parameters. Use propagate().2) Update the parameters using gradient descent rule for w and b.&quot;&quot;&quot;costs = []for i in range(num_iterations):# Cost and gradient calculationgrads, cost = propagate(w, b, X, Y)# Retrieve derivatives from gradsdw = grads[&quot;dw&quot;]db = grads[&quot;db&quot;]# update rulew = w - learning_rate * dwb = b - learning_rate * db# Record the costsif i % 100 == 0:costs.append(cost)# Print the cost every 100 training examplesif print_cost and i % 100 == 0:print (&quot;Cost after iteration %i: %f&quot; %(i, cost))params = &#123;&quot;w&quot;: w,&quot;b&quot;: b&#125;grads = &#123;&quot;dw&quot;: dw,&quot;db&quot;: db&#125;return params, grads, costs 123456params, grads, costs = optimize(w, b, X, Y, num_iterations= 100, learning_rate = 0.009, print_cost = False)print (&quot;w = &quot; + str(params[&quot;w&quot;]))print (&quot;b = &quot; + str(params[&quot;b&quot;]))print (&quot;dw = &quot; + str(grads[&quot;dw&quot;]))print (&quot;db = &quot; + str(grads[&quot;db&quot;])) Output:w = [[ 0.19033591][ 0.12259159]]b = 1.92535983008dw = [[ 0.67752042][ 1.41625495]]db = 0.219194504541 Prediction123456789101112131415161718192021222324252627def predict(w, b, X):&apos;&apos;&apos;Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)Arguments:w -- weights, a numpy array of size (num_px * num_px * 3, 1)b -- bias, a scalarX -- data of size (num_px * num_px * 3, number of examples)Returns:Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X&apos;&apos;&apos;m = X.shape[1]Y_prediction = np.zeros((1, m))w = w.reshape(X.shape[0], 1)# Compute vector &quot;A&quot; predicting the probabilities of a cat being present in the pictureA = sigmoid(np.dot(w.T, X) + b)for i in range(A.shape[1]):# Convert probabilities a[0,i] to actual predictions p[0,i]Y_prediction[0, i] = 1 if A[0, i] &gt; 0.5 else 0assert(Y_prediction.shape == (1, m))return Y_prediction Step1.Initialize (w,b) Optimize the loss iteratively to learn parameters (w,b): computing the cost and its gradient updating the parameters using gradient descent Use the learned (w,b) to predict the labels for a given set of examples Merge all functions Implement the model function: Y_prediction for your predictions on the test set Y_prediction_train for your predictions on the train set w, costs, grads for the outputs of optimize() 123456789101112131415161718192021222324252627282930313233343536373839404142434445def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):&quot;&quot;&quot;Builds the logistic regression model by calling the function implemented previouslyArguments:X_train -- training set represented by a numpy array of shape (num_px * num_px * 3, m_train)Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train)X_test -- test set represented by a numpy array of shape (num_px * num_px * 3, m_test)Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test)num_iterations -- hyperparameter representing the number of iterations to optimize the parameterslearning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()print_cost -- Set to true to print the cost every 100 iterationsReturns:d -- dictionary containing information about the model.&quot;&quot;&quot;# initialize parameters with zerosw, b = initialize_with_zeros(X_train.shape[0])# Gradient descentparameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost);# Retrieve parameters w and b from dictionary &quot;parameters&quot;w = parameters[&quot;w&quot;]b = parameters[&quot;b&quot;]# Predict test/train set examplesY_prediction_test = predict(w, b, X_test)Y_prediction_train = predict(w, b, X_train)# Print train/test Errorsprint(&quot;train accuracy: &#123;&#125; %&quot;.format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))print(&quot;test accuracy: &#123;&#125; %&quot;.format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))d = &#123;&quot;costs&quot;: costs,&quot;Y_prediction_test&quot;: Y_prediction_test,&quot;Y_prediction_train&quot; : Y_prediction_train,&quot;w&quot; : w,&quot;b&quot; : b,&quot;learning_rate&quot; : learning_rate,&quot;num_iterations&quot;: num_iterations&#125;return d Run the following cell to train your model.1d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True) Output:Cost after iteration 0: 0.693147Cost after iteration 100: 0.584508Cost after iteration 200: 0.466949Cost after iteration 300: 0.376007Cost after iteration 400: 0.331463Cost after iteration 500: 0.303273Cost after iteration 600: 0.279880Cost after iteration 700: 0.260042Cost after iteration 800: 0.242941Cost after iteration 900: 0.228004Cost after iteration 1000: 0.214820Cost after iteration 1100: 0.203078Cost after iteration 1200: 0.192544Cost after iteration 1300: 0.183033Cost after iteration 1400: 0.174399Cost after iteration 1500: 0.166521Cost after iteration 1600: 0.159305Cost after iteration 1700: 0.152667Cost after iteration 1800: 0.146542Cost after iteration 1900: 0.140872train accuracy: 99.04306220095694 %test accuracy: 70.0 % Comment:Training accuracy is close to 100%. This is a good sanity check: your model is working and has high enough capacity to fit the training data. Test error is 68%. It is actually not bad for this simple model, given the small dataset we used and that logistic regression is a linear classifier. Also, you see that the model is clearly overfitting the training data. ReferencesNeural Networks and Deep LearningImplementing a Neural Network from Scratch in Python – An Introductionhttps://stats.stackexchange.com/questions/211436]]></content>
      <categories>
        <category>Technology</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Logistic Regression</tag>
        <tag>Neural Network</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python - Vectorization and Broadcasting]]></title>
    <url>%2F2018%2F02%2F08%2FPython-Broadcasting%2F</url>
    <content type="text"><![CDATA[VectorizationIn the course Neural Networks and Deep Learning, Andrew Ng introduces vetorization in machine learning by giving the following examples: 123456789101112131415161718192021222324import numpy as npimport timea = np.random.rand(1000000)b = np.random.rand(1000000)# vectorizationtic = time.time()c = np.dot(a,b)toc = time.time()print(c)print("Vectorization:" + str(1000*(toc-tic)) + "ms")c = 0# vectorizationtic = time.time()for i in range(1000000):c += a[i]*b[i]toc = time.time()print(c)print("For loop:" + str(1000*(toc-tic)) + "ms") The above code uses vetorization and for loop to do the same calculation. However, the for loop version cost much more time than the vectorization version. Output:249888.154501Vectorization:2.2249221801757812ms249888.154501For loop:599.0450382232666ms The above example indicates that in python it’s more efficient to use vectorization instead of for loop. This kind of technique is also called SIMD(single instruction multiple data) in CPU/GPU parallel processing. Broadcasting The term broadcasting describes how numpy treats arrays with different shapes during arithmetic operations. Subject to certain constraints, the smaller array is “broadcast” across the larger array so that they have compatible shapes. Broadcasting provides a means of vectorizing array operations so that looping occurs in C instead of Python. It does this without making needless copies of data and usually leads to efficient algorithm implementations. NumPy operations are usually done on pairs of arrays on an element-by-element basis. In the simplest case, the two arrays must have exactly the same shape, as in the following example: 1234&gt;&gt;&gt; a = np.array([1.0, 2.0, 3.0])&gt;&gt;&gt; b = np.array([2.0, 2.0, 2.0])&gt;&gt;&gt; a * barray([ 2., 4., 6.]) NumPy’s broadcasting rule relaxes this constraint when the arrays’ shapes meet certain constraints. The simplest broadcasting example occurs when an array and a scalar value are combined in an operation: 1234&gt;&gt;&gt; a = np.array([1.0, 2.0, 3.0])&gt;&gt;&gt; b = 2.0&gt;&gt;&gt; a * barray([ 2., 4., 6.]) The result is equivalent to the previous example where b was an array. We can think of the scalar b being stretched during the arithmetic operation into an array with the same shape as a. The new elements in b are simply copies of the original scalar. The stretching analogy is only conceptual. NumPy is smart enough to use the original scalar value without actually making copies, so that broadcasting operations are as memory and computationally efficient as possible. The code in the second example is more efficient than that in the first because broadcasting moves less memory around during the multiplication (b is a scalar rather than an array). General Broadcasting RulesWhen operating on two arrays, NumPy compares their shapes element-wise. It starts with the trailing dimensions, and works its way forward. Two dimensions are compatible when they are equal one of them is 1 Arrays don’t have to have the same number of dimensions. For example, if you have a 256x256x3 array of RGB values, and you want to scale each color in the image by a different value, you can multiply the image by a one-dimensional array with 3 values. Image (3d array): 256 x 256 x 3Scale (1d array): 3Result (3d array): 256 x 256 x 3 When either of the dimensions compared is one, the other is used. In other words, dimensions with size 1 are stretched or “copied” to match the other. A (4d array): 8 x 1 x 6 x 1B (3d array): 7 x 1 x 5Result (4d array): 8 x 7 x 6 x 5 A (2d array): 5 x 4B (1d array): 1Result (2d array): 5 x 4 A (2d array): 5 x 4B (1d array): 4Result (2d array): 5 x 4 A (3d array): 15 x 3 x 5B (3d array): 15 x 1 x 5Result (3d array): 15 x 3 x 5 A (3d array): 15 x 3 x 5B (2d array): 3 x 5Result (3d array): 15 x 3 x 5 Here are examples of shapes that do not broadcast: A (1d array): 3B (1d array): 4 # trailing dimensions do not match A (2d array): 2 x 1B (3d array): 8 x 4 x 3 # second from last dimensions mismatched References Neural Networks and Deep Learning Broadcasting — NumPy v1.12 Manual]]></content>
      <categories>
        <category>Technology</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Python</tag>
        <tag>NumPy</tag>
        <tag>vectorization</tag>
        <tag>broadcasting</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google Analytics Introduction]]></title>
    <url>%2F2018%2F02%2F07%2FWeekly-Report-20180207%2F</url>
    <content type="text"><![CDATA[In order to better evaluate how the website works, I use Google Analytics to monitor statistics of the website. Here is a brief introduction of how Google Analytics works and what we can get from it. HomeIn home page there are portals to most important statistics. Real-TimeIn Real-Time page, we can monitor our website in real-time mode, which is useful for website adminstrator. In the picture we can see that there is no active users on site. AudienceIn Audience page, information of users are listed. We can see the number of users, sessions/pageviews of users and demographics of users. AquisitionIn Aquisition page, it shows how users are directed to this website, which is useful for analyzing how to get more users. BehaviorIn Behavior page, different kinds of website behaviors are presented. This section could help website administrator to evaluate the efficiency and accessibility of website. In this section I recommend Behavior Flow cause it shows how users jump between pages. ReportHere attached sample Google Analytics report for this website. Analytics Website Monitor Acquisition OverviewAnalytics Website Monitor Behavior FlowAnalytics Website Monitor LocationAnalytics Website Monitor Overview]]></content>
      <categories>
        <category>Documentation</category>
      </categories>
      <tags>
        <tag>Google Analytics</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PCA - Mathematics (1)]]></title>
    <url>%2F2018%2F01%2F30%2FPCA-Mathematical-principle%2F</url>
    <content type="text"><![CDATA[Principal component analysis (PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components. Vector representation and Dimensionality reduction of dataIn general, in data mining and machine learning, data are represented as vectors.For example:$$ (500,240,25,13,2312.15)^𝖳 $$ As we know, the scale of dimensionality of data is in proportion to complexity of machine learning algorithm, so we can reduce dimensionality to simplify calculation. Obviuosly, dimensionality reduction means loss of information. However, due to the correlation among data, we could minimize the loss in the above process, which is the purpose of PCA. Change of basesInner productInner product of two vectors is defined as: $$ (a_1,a_2,⋯,a_n)^𝖳⋅(b_1,b_2,⋯,b_n)^𝖳=a_1b_1+a_2b_2+⋯+a_nb_n $$ and $$ A⋅B=|A||B|cos(a) $$ Let |B| = 1, that is $ A⋅B=|A|cos(a) $. The above definition could be explained that the inner product of A and B equals the vector length projected from A to B. BaseTo describe a vector, we need a set of bases. Then the vector could be represented as the combination of projections to all bases. Usually, we choose (1,0) and (0,1) as bases, but actually we can choose any two linearly independent vectors as bases. For example, we can use $ (\frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}}) $ and $ (\frac{1}{\sqrt{2}}, -\frac{1}{\sqrt{2}}) $ as new bases to represent the same vector. Matrix representation of form changeFor example, we want to transform (3, 2) based on new bases $ (\frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}}) $ and $ (\frac{1}{\sqrt{2}}, -\frac{1}{\sqrt{2}}) $, which could be represented by the following form: $$\left(\begin{matrix}\frac{1}{\sqrt{2}} &amp; \frac{1}{\sqrt{2}} \\-\frac{1}{\sqrt{2}} &amp; \frac{1}{\sqrt{2}}\end{matrix}\right)\left(\begin{matrix}1 &amp; 2 &amp; 3 \\1 &amp; 2 &amp; 3\end{matrix}\right)=\left(\begin{matrix}\frac{2}{\sqrt{2}} &amp; \frac{4}{\sqrt{2}} &amp; \frac{6}{\sqrt{2}} \\0 &amp; 0 &amp; 0\end{matrix}\right)$$ In general, if we have M N-dimesion vector and want to transform them into R N-dimesion new spaces, we first construct matrix A combining R bases by row, then construct matrix B combining vectors by column. The product of A and B is the result, where the column in AB is transformed from column in A. The above shows an explanation of matrix product:product of two matrices(AB) means to transform each column vector in B to the new space with rows in A as bases.]]></content>
      <categories>
        <category>Technology</category>
      </categories>
      <tags>
        <tag>Mathematics</tag>
        <tag>Machine Learning</tag>
        <tag>PCA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ECMAScript 6 features (3)]]></title>
    <url>%2F2018%2F01%2F30%2FECMAScript-6-3%2F</url>
    <content type="text"><![CDATA[Data-Structure Set12345var s = new Set();[2,3,5,4,5,2,2].map(x =&gt; s.add(x))for (i of s) &#123;console.log(i)&#125;// 2 3 4 5 Methods: size：Returns the number of values in the Set object. add(value)：Appends a new element with the given value to the Set object. Returns the Set object. delete(value)：Removes the element associated to the value and returns the value that has(value)：Returns a boolean asserting whether an element is present with the given value in the Set object or not. clear()：Removes all elements from the Set object. Tips: Set constructor could receive an array to eliminate duplicate. 12const items = new Set([1, 2, 3, 4, 5, 5, 5, 5]);items.size // 5 For set, 5 and ‘5’ are different, and objects are always different. 1234567let set = new Set();set.add(&#123;&#125;);set.size // 1set.add(&#123;&#125;);set.size // 2 Iteration keys()：return an iterator for keys values()：return an iterator for values entries()：Returns a new Iterator object that contains an array of [value, value] for each element in the Set object, in insertion order. 12345678910111213141516171819202122let set = new Set(['red', 'green', 'blue']);for (let item of set.keys()) &#123;console.log(item);&#125;// red// green// bluefor (let item of set.values()) &#123;console.log(item);&#125;// red// green// bluefor (let item of set.entries()) &#123;console.log(item);&#125;// ["red", "red"]// ["green", "green"]// ["blue", "blue"] forEach()：Calls callbackFn once for each value present in the Set object, in insertion order.If a thisArg parameter is provided to forEach, it will be used as the this value for each callback. 12345set = new Set([1, 4, 9]);set.forEach((value, key) =&gt; console.log(key + ' : ' + value))// 1 : 1// 4 : 4// 9 : 9 MapProperties/Methodssize12345const map = new Map();map.set('foo', true);map.set('bar', false);map.size // 2 set(key, value)12345const m = new Map();m.set('edition', 6)m.set(262, 'standard')m.set(undefined, 'nah') get(key)123456const m = new Map();const hello = function() &#123;console.log('hello');&#125;;m.set(hello, 'Hello ES6!') // key is a function!m.get(hello) // Hello ES6! has(key)return a boolean shows if a key exists in the map object.12345678910const m = new Map();m.set('edition', 6);m.set(262, 'standard');m.set(undefined, 'nah');m.has('edition') // truem.has('years') // falsem.has(262) // truem.has(undefined) // true delete(key)123456const m = new Map();m.set(undefined, 'nah');m.has(undefined) // truem.delete(undefined)m.has(undefined) // false clear()clear all elements, no return value1234567let map = new Map();map.set('foo', true);map.set('bar', false);map.size // 2map.clear()map.size // 0 override:1234567const map = new Map();map.set(1, 'aaa').set(1, 'bbb');map.get(1) // "bbb" ConvertConvert Map to Array:12345const myMap = new Map().set(true, 7).set(&#123;foo: 3&#125;, ['abc']);[...myMap]// [ [ true, 7 ], [ &#123; foo: 3 &#125;, [ 'abc' ] ] ] Convert Array to Map:12345678new Map([[true, 7],[&#123;foo: 3&#125;, ['abc']]])// Map &#123;// true =&gt; 7,// Object &#123;foo: 3&#125; =&gt; ['abc']// &#125; Convert Map to Object:If keys for map are all strings, the convertion is accepted.12345678910111213function strMapToObj(strMap) &#123;let obj = Object.create(null);for (let [k,v] of strMap) &#123;obj[k] = v;&#125;return obj;&#125;const myMap = new Map().set('yes', true).set('no', false);strMapToObj(myMap)// &#123; yes: true, no: false &#125; Convert Object to Map:12345678910function objToStrMap(obj) &#123;let strMap = new Map();for (let k of Object.keys(obj)) &#123;strMap.set(k, obj[k]);&#125;return strMap;&#125;objToStrMap(&#123;yes: true, no: false&#125;)// Map &#123;"yes" =&gt; true, "no" =&gt; false&#125; Convert Map to JSON:(1) Keys are stings1234567function strMapToJson(strMap) &#123;return JSON.stringify(strMapToObj(strMap));&#125;let myMap = new Map().set('yes', true).set('no', false);strMapToJson(myMap)// '&#123;"yes":true,"no":false&#125;' (2)Keys contain non string1234567function mapToArrayJson(map) &#123;return JSON.stringify([...map]);&#125;let myMap = new Map().set(true, 7).set(&#123;foo: 3&#125;, ['abc']);mapToArrayJson(myMap)// '[[true,7],[&#123;"foo":3&#125;,["abc"]]]' Convert JSON to Map:123456function jsonToStrMap(jsonStr) &#123;return objToStrMap(JSON.parse(jsonStr));&#125;jsonToStrMap('&#123;"yes": true, "no": false&#125;')// Map &#123;'yes' =&gt; true, 'no' =&gt; false&#125; Differences between Object and Map object has a prototype so there are default keys can be bypassed using map = Object.create(null) object keys are string whereas map keys can be anything map keeps track of size use maps over objects when keys are unknown until run time use objects when there is logic that operates on individual elements WeakSet iterate through providing keys only not enumerable unique object references only accept objects Differences between Set and WeakSet WeakSets are collections of object types only references to objects in the collection are held weakly 123456789var myWeakSet = new WeakSet();var foo = &#123;&#125;;var bar = &#123;&#125;;myWeakSet.add(foo);myWeakSet.has(bar); // falsemyWeakSet.has(foo); // truemyWeakSet.delete(foo);myWeakSet.add(&#123; kobe: 24 &#125;); // But because the added object has no other references, it will not be held in the set WeakMap iterate through providing keys only not enumerable unique object or function references does not accept primitive data types as keys 12345678var myWeakMap = new WeakMap();var obj1 = &#123;&#125;;var obj2 = function()&#123;&#125;;myWeakMap.set(obj1, "cat");myWeakMap.set(obj2, 24);myWeakMap.has(obj1); // truemyWeakMap.get(obj2); // 24myWeakMap.delete(obj1);]]></content>
      <categories>
        <category>Technology</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ECMAScript 6 features (2)]]></title>
    <url>%2F2018%2F01%2F28%2FECMAScript-6-2%2F</url>
    <content type="text"><![CDATA[FunctionDefault Parameter ValuesSimple and intuitive default values for function parameters. 1234function f (x, y = 7, z = 42) &#123;return x + y + z&#125;f(1) === 50 Rest ParameterAggregation of remaining arguments into single parameter of variadic functions. 1234function f (x, y, ...a) &#123;return (x + y) * a.length&#125;f(1, 2, "hello", true, 7) === 9 Spread OperatorSpreading of elements of an iterable collection (like an array or even a string) into both literal elements and individual function parameters. 12345678910var params = [ "hello", true, 7 ]var other = [ 1, 2, ...params ] // [ 1, 2, "hello", true, 7 ]function f (x, y, ...a) &#123;return (x + y) * a.length&#125;f(1, 2, ...params) === 9var str = "foo"var chars = [ ...str ] // [ "f", "o", "o" ] Strict modeSince ES5, strict mode could be applied within function.In ES6, if a function uses default parameter value, rest parameter or spread operator, strict mode couldn’t be used in the function. Name 12function foo() &#123;&#125;foo.name // "foo" Arrow Functions1var f = v =&gt; v; equals: 123var f = function(v) &#123;return v;&#125;; If there is no arguments or more than 1 arguments, use bracket. 123456789var f = () =&gt; 5;// equalsvar f = function () &#123; return 5 &#125;;var sum = (num1, num2) =&gt; num1 + num2;// equalsvar sum = function(num1, num2) &#123;return num1 + num2;&#125;; Example of arrow function combining with rest parameters: 123456789const numbers = (...nums) =&gt; nums;numbers(1, 2, 3, 4, 5)// [1,2,3,4,5]const headAndTail = (head, ...tail) =&gt; [head, tail];headAndTail(1, 2, 3, 4, 5)// [1,[2,3,4,5]] Tail CallDefinition: call one function at the last step of another function.123function f(x)&#123;return g(x);&#125; Tail Recursion A recursive function is tail recursive when recursive call is the last thing executed by the function. 123456function factorial(n, total) &#123;if (n === 1) return total;return factorial(n - 1, n * total);&#125;factorial(5, 1) // 120 The tail recursive functions considered better than non tail recursive functions as tail-recursion can be optimized by compiler. The idea used by compilers to optimize tail-recursive functions is simple, since the recursive call is the last statement, there is nothing left to do in the current function, so saving the current function’s stack frame is of no use (See this for more details). Example: (Fibonacci) Non tail recursive: 123456789function Fibonacci (n) &#123;if ( n &lt;= 1 ) &#123;return 1&#125;;return Fibonacci(n - 1) + Fibonacci(n - 2);&#125;Fibonacci(10) // 89Fibonacci(100) // overflowFibonacci(500) // overflow Tail recursive: 123456789function Fibonacci2 (n , ac1 = 1 , ac2 = 1) &#123;if( n &lt;= 1 ) &#123;return ac2&#125;;return Fibonacci2 (n - 1, ac2, ac1 + ac2);&#125;Fibonacci2(100) // 573147844013817200000Fibonacci2(1000) // 7.0330367711422765e+208Fibonacci2(10000) // Infinity]]></content>
      <categories>
        <category>Technology</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ECMAScript 6 features (1)]]></title>
    <url>%2F2018%2F01%2F28%2FECMAScript-6-1%2F</url>
    <content type="text"><![CDATA[constSupport for constants, variables which cannot be re-assigned new content. Notice: this only makes the variable itself immutable, not its assigned content (for instance, in case the content is an object, this means the object itself can still be altered). 12345678const foo = &#123;&#125;;// add an attribute to foo, successfoo.prop = 123;foo.prop // 123// assign foo to another object, errorfoo = &#123;&#125;; // TypeError: "foo" is read-only letBlock-scoped variables (and constants) without hoisting. ‘let’ only validates in scope: 123456789101112131415&#123;let a = 10;var b = 1;&#125;a // ReferenceError: a is not defined.b // 1which is useful in for loop:for (let i = 0; i &lt; 10; i++) &#123;// ...&#125;console.log(i);// ReferenceError: i is not defined Temporal dead zone (TDZ)If a variable is declared by ‘let’ in a block scope, it’s binding to the block scope and refrain from outside. 1234567891011if (true) &#123;// TDZ starttmp = 'abc'; // ReferenceErrorconsole.log(tmp); // ReferenceErrorlet tmp; // TDZ endconsole.log(tmp); // undefinedtmp = 123;console.log(tmp); // 123&#125; Repeat declaration is not allowed 1234567891011// errorfunction func() &#123;let a = 10;var a = 1;&#125;// errorfunction func() &#123;let a = 10;let a = 1;&#125; ES6 has 6 methods of variable declarationES5 has two methods of variable declaration: var, function;ES6 has 4 more methods: let, const, import, class.]]></content>
      <categories>
        <category>Technology</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello world]]></title>
    <url>%2F2018%2F01%2F27%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Hello world This website is Yu Liu’s homepage, built by Hexo+Github pages. Contents are written with Markdown syntax. This website is for: 1. Share idea “Do not go gentle into that good night” 2. Code review1234567@requires_authorizationclass SomeClass:passif __name__ == '__main__':# A commentprint 'hello world' 3. Photography 4. Schedule and plan Set up TensorFlow environment Build personal website Solve algorithm problems Learn ASP.NET MVC Framework]]></content>
      <categories>
        <category>Documentation</category>
      </categories>
  </entry>
</search>
